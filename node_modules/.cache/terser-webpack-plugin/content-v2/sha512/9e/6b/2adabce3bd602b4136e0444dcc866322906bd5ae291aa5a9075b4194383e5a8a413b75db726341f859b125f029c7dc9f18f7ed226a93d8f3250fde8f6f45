{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[15],{237:function(e,t,a){\"use strict\";a.r(t);var s=a(0),n=Object(s.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":e.$parent.slotKey}},[a(\"h1\",{attrs:{id:\"duplicate-files-checker\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#duplicate-files-checker\"}},[e._v(\"#\")]),e._v(\" Duplicate Files Checker\")]),e._v(\" \"),a(\"h2\",{attrs:{id:\"how-to-determine-same-file\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#how-to-determine-same-file\"}},[e._v(\"#\")]),e._v(\" How to determine same file\")]),e._v(\" \"),a(\"p\",[e._v(\"Generally, we use checksum of files to check if files are same or not. We usually use MD5 or SHA256 to get checksum of files. On Ubuntu, we could use command \"),a(\"code\",[e._v(\"hd5sum\")]),e._v(\" or \"),a(\"code\",[e._v(\"sha256sum\")]),e._v(\".\")]),e._v(\" \"),a(\"div\",{staticClass:\"custom-block tip\"},[a(\"p\",{staticClass:\"custom-block-title\"},[e._v(\"TIP\")]),e._v(\" \"),a(\"p\",[e._v(\"There is no perfect hash function yet, which means collision may happen during hashing.\")])]),e._v(\" \"),a(\"p\",[e._v(\"When using these commands, you have to notice that the two files could be determined as same file only all content are same.\")]),e._v(\" \"),a(\"h2\",{attrs:{id:\"how-to-store-and-compare-different-files\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#how-to-store-and-compare-different-files\"}},[e._v(\"#\")]),e._v(\" How to store and compare different files\")]),e._v(\" \"),a(\"h3\",{attrs:{id:\"store-and-compare-content\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#store-and-compare-content\"}},[e._v(\"#\")]),e._v(\" store and compare content\")]),e._v(\" \"),a(\"p\",[e._v(\"Usually, a directory contains lots of files, and we want to compare them to check if they are same. My goal is checking about 2 millions files, I cannot use data structure like Tree. In this case, I am using HashTable to store the checksum and its filename. They separately are Key and Value.\")]),e._v(\" \"),a(\"h3\",{attrs:{id:\"store-and-compare-filename\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#store-and-compare-filename\"}},[e._v(\"#\")]),e._v(\" store and compare filename\")]),e._v(\" \"),a(\"p\",[e._v(\"To compare the filename in different folders, the fastest way is still hashing. I used another hash table to store the filename as key and it's absolute path as value. To link these two hash tables, the value of the content hash table is also the key of the filename hash table.\")]),e._v(\" \"),a(\"h2\",{attrs:{id:\"how-to-loop-directories\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#how-to-loop-directories\"}},[e._v(\"#\")]),e._v(\" How to loop directories\")]),e._v(\" \"),a(\"p\",[e._v(\"In this step, different programming language has different method to implement it. But the algorithm is same, which is using recursion to loop the subdirectories and files. The example pseudo code is shown below.\")]),e._v(\" \"),a(\"div\",{staticClass:\"language-python line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[a(\"code\",[e._v(\"check_duplicate\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[e._v(\"(\")]),e._v(\"path\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[e._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[e._v(\":\")]),e._v(\"\\n    \\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[e._v(\"for\")]),e._v(\" files \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[e._v(\"in\")]),e._v(\" list_files\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[e._v(\":\")]),e._v(\"\\n        \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[e._v(\"# check duplicate\")]),e._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[e._v(\"for\")]),e._v(\" folder \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[e._v(\"in\")]),e._v(\" list_directories\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[e._v(\":\")]),e._v(\"\\n        check_duplicate\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[e._v(\"(\")]),e._v(\"path_to_folder\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[e._v(\")\")]),e._v(\"\\n\\n\")])]),e._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[e._v(\"1\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"2\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"3\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"4\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"5\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"6\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"7\")]),a(\"br\")])]),a(\"p\",[e._v(\"The complete run-able code is on \"),a(\"a\",{attrs:{href:\"https://github.com/jinchenxiangdan/Tools/blob/master/DuplicateFileChecker/duplicate_file_checker.py\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"github\"),a(\"OutboundLink\")],1)]),e._v(\" \"),a(\"h2\",{attrs:{id:\"references\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#references\"}},[e._v(\"#\")]),e._v(\" REFERENCES\")]),e._v(\" \"),a(\"p\",[a(\"a\",{attrs:{href:\"https://www.versity.com/blog/data-integrity-checksums\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"Data Integrity Checksums\"),a(\"OutboundLink\")],1)])])}),[],!1,null,null,null);t.default=n.exports}}]);","extractedComments":[]}